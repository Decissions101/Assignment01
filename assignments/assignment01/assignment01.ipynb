{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7630800",
   "metadata": {},
   "source": [
    "# Assignment 01\n",
    "\n",
    "This assignment consists of two tasks with subtasks. Every subtask has a point value and lists expectations for answers. Please read both task and expectations carefully before answering.\n",
    "\n",
    "### Hand-in Instructions\n",
    "\n",
    "Submit a single `.ipynb` file with all outputs saved. The notebook must be fully self-contained and ready to read without running any cells.\n",
    "\n",
    "### Overview\n",
    "\n",
    "| Task  | Topic                                     | Points  |\n",
    "| ----- | ----------------------------------------- | ------- |\n",
    "| **1** | **PCA**                                   |         |\n",
    "| 1.1   | 3D scatter plot                           | 5       |\n",
    "| 1.2   | 2D scatter plot                           | 5       |\n",
    "| 1.3   | Interpreting variance                     | 10      |\n",
    "| 1.4   | Variance and geometry                     | 10      |\n",
    "| **2** | **Breast Cancer Classification Pipeline** |         |\n",
    "| 2.1   | Exploratory Data Analysis                 | 30      |\n",
    "| 2.2   | Train/Test Split                          | 5       |\n",
    "| 2.3   | Baseline Model                            | 5       |\n",
    "| 2.4   | Kitchen Sink Model                        | 10      |\n",
    "| 2.5   | Build Your Own Pipeline                   | 20      |\n",
    "|       | **Total**                                 | **100** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a799d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155834c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "from assignment_utils import generate_annulus_4d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3848b85",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: PCA\n",
    "\n",
    "You've been given a mysterious dataset with **4 dimensions** (F1, F2, F3, F4). We can't directly visualize 4D data, but we can look at 3 dimensions at a time and use color for the 4th.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4d, radius = generate_annulus_4d()\n",
    "df = pd.DataFrame(data_4d, columns=[\"F1\", \"F2\", \"F3\", \"F4\"])\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Let's visualize the first 3 dimensions (F1, F2, F3) in 3D\n",
    "# The 4th dimension (F4) is represented as color\n",
    "fig = px.scatter_3d(\n",
    "    df,\n",
    "    x=\"F1\",\n",
    "    y=\"F2\",\n",
    "    z=\"F3\",\n",
    "    color=df[\"F4\"],\n",
    "    color_continuous_scale=\"viridis\",\n",
    "    title=\"3D View of the 4D Dataset (F1, F2, F3, color=F4)\",\n",
    "    labels={\"color\": \"F4\"},\n",
    ")\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472977bf",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)\n",
    "\n",
    "**PCA** is a technique that finds new axes (called _principal components_) that capture the most variance in the data.\n",
    "\n",
    "**Mathematical formulation:**\n",
    "\n",
    "1. **Standardize** the data: $\\mathbf{Z} = \\frac{\\mathbf{X} - \\boldsymbol{\\mu}}{\\boldsymbol{\\sigma}}$\n",
    "\n",
    "2. Compute the **covariance matrix**: $\\mathbf{C} = \\frac{1}{n-1} \\mathbf{Z}^T \\mathbf{Z}$\n",
    "\n",
    "3. Find the **eigenvectors** and **eigenvalues** of $\\mathbf{C}$:\n",
    "   $$\\mathbf{C} \\mathbf{v}_i = \\lambda_i \\mathbf{v}_i$$\n",
    "4. **Project** the data onto the principal components: $\\mathbf{Z}_{PC} = \\mathbf{Z} \\mathbf{V}$\n",
    "\n",
    "where $\\mathbf{V} = [\\mathbf{v}_1, \\mathbf{v}_2, \\ldots]$ are the eigenvectors sorted by decreasing eigenvalue $\\lambda_i$.\n",
    "\n",
    "**Key ideas:**\n",
    "\n",
    "- **PC1** points in the direction of maximum variance (largest $\\lambda$)\n",
    "- **PC2** is perpendicular to PC1 and captures the next most variance\n",
    "- The **explained variance ratio** for each PC is: $\\frac{\\lambda_i}{\\sum_j \\lambda_j}$\n",
    "- The eigenvectors $\\mathbf{V} = [\\mathbf{v}_1, \\mathbf{v}_2, \\ldots]$ are basis vectors for the principal component space. Any data vector can be completely reconstructed by a linear combination of these principal component basis vectors.\n",
    "\n",
    "If the data lies on a lower-dimensional subspace, PCA can reveal it by finding the directions that matter most.\n",
    "\n",
    "Let's standardize the data first (so all features have equal scale), then apply PCA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize and apply PCA\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "\n",
    "pca = PCA()\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Create a DataFrame with principal components\n",
    "df_pca = pd.DataFrame(data_pca, columns=[\"PC1\", \"PC2\", \"PC3\", \"PC4\"])\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Cumulative explained variance ratio:\", np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "# Get the PC directions (loadings) - each row is a PC, each column is a feature\n",
    "components = pca.components_  # Shape: (4, 4) - 4 PCs x 4 features\n",
    "\n",
    "# Create the scatter plot of scaled data (first 3 features)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the data points\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=data_scaled[:, 0],\n",
    "        y=data_scaled[:, 1],\n",
    "        z=data_scaled[:, 2],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=2, opacity=0.5),\n",
    "        name=\"Data\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add arrows for PC1, PC2, PC3 directions\n",
    "# Arrow length proportional to explained variance ratio (with minimum for visibility)\n",
    "colors = [\"red\", \"green\", \"blue\"]\n",
    "base_scale = 5  # Base scale factor\n",
    "min_scale = 0.5  # Minimum scale so small PCs are still visible\n",
    "\n",
    "for i in range(3):\n",
    "    pc_direction = components[i, :3]  # First 3 components of each PC\n",
    "    # Scale by explained variance ratio - longer arrow = more variance\n",
    "    # Use minimum scale so all arrows are visible\n",
    "    variance_ratio = pca.explained_variance_ratio_[i] / max(\n",
    "        pca.explained_variance_ratio_\n",
    "    )\n",
    "    scale = max(base_scale * variance_ratio, min_scale)\n",
    "\n",
    "    # Arrow line\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[0, pc_direction[0] * scale],\n",
    "            y=[0, pc_direction[1] * scale],\n",
    "            z=[0, pc_direction[2] * scale],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=colors[i], width=8),\n",
    "            name=f\"PC{i + 1} ({pca.explained_variance_ratio_[i]:.1%} var)\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Arrow head (cone)\n",
    "    fig.add_trace(\n",
    "        go.Cone(\n",
    "            x=[pc_direction[0] * scale],\n",
    "            y=[pc_direction[1] * scale],\n",
    "            z=[pc_direction[2] * scale],\n",
    "            u=[pc_direction[0]],\n",
    "            v=[pc_direction[1]],\n",
    "            w=[pc_direction[2]],\n",
    "            colorscale=[[0, colors[i]], [1, colors[i]]],\n",
    "            showscale=False,\n",
    "            sizemode=\"absolute\",\n",
    "            sizeref=0.3,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Principal Component Directions (arrow length ∝ variance explained)\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"F1 (scaled)\",\n",
    "        yaxis_title=\"F2 (scaled)\",\n",
    "        zaxis_title=\"F3 (scaled)\",\n",
    "    ),\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8317af",
   "metadata": {},
   "source": [
    "### Task 1.1 3D scatter plot\n",
    "\n",
    "- Task: Create a 3D scatter plot using PC1, PC2, PC3 as axes\n",
    "- Points: 5\n",
    "- Expectations: A working 3D scatter plot of the PCA-transformed data (similar in style to the first 3D plot). No further analysis or comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "fig = px.scatter_3d(\n",
    "    df_pca,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    z=\"PC3\",\n",
    "    color=df_pca[\"PC4\"],\n",
    "    color_continuous_scale=\"viridis\",\n",
    "    title=\"3D PCA Projectrion (color = PC4)\",\n",
    "    labels={\"color\": \"F4\"},\n",
    ")\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fce4b7",
   "metadata": {},
   "source": [
    "### Task 1.2 2D scatter plot\n",
    "\n",
    "- Task: Create a 2D scatter plot using PC1, PC2 as axes\n",
    "- Points: 5\n",
    "- Expectations: A working 2D scatter plot of the PCA-transformed data. No further analysis or comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689673ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Test to see what data we have\n",
    "# print(df.columns.tolist())\n",
    "# print(df.shape)\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_pca,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    color=\"PC4\",\n",
    "    hover_data=[\"PC3\", \"PC4\"],\n",
    "    color_continuous_scale=\"viridis\",\n",
    "    title=\"2D PCA Projection (x=PC1, y=PC2, hover=PC3, color=PC4)\",\n",
    "    labels={\"color\": \"PC4\"},\n",
    ")\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5cd7d",
   "metadata": {},
   "source": [
    "### Task 1.3 Interpreting variance\n",
    "\n",
    "- Task: How much variance do PC1 and PC2 capture together? Based on this, what can you conclude about the original 4D dataset?\n",
    "- Points: 10\n",
    "- Expectations: A written response (1 paragraph).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e308ce",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa445270",
   "metadata": {},
   "source": [
    "PC1Var = 50.9%\n",
    "PC2Var = 49.1%\n",
    "\n",
    "SumVar = PC1Var + PC2Var = 50.9% + 49.1% = 100%. This means that of the original 4D dataset PC1 and PC2 contains all the information while the other two don't contribute meaningfully to the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f0819",
   "metadata": {},
   "source": [
    "### Task 1.4 Variance and geometry\n",
    "\n",
    "- Task: If PC1 explained 90% of the variance and PC2 only 10%, what shape would you expect the data to form? Now compare this to your actual ~50/50 split — what does this tell you about the geometry of your data?\n",
    "- Points: 10\n",
    "- Expectations: A written response (1 paragraph).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968012e8",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818df1b4",
   "metadata": {},
   "source": [
    "Since data variance is the measure of how far each data point is from the mean. A 90% variance in PC1 would make the vector showing variance longer. This would then stretch the circle in the direction and opposite direction of the vector making it an oval. Since the PC2 vector is now only 10% we would se a ratio between the \"height\" and \"width\" of the oval as close to 9:1, since there is 0,02 noise put into the assignment_utils.py file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0e1ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Breast Cancer Classification Pipeline\n",
    "\n",
    "Now let's apply what you've learned to a real-world dataset: the **Wisconsin Breast Cancer** dataset. This dataset contains measurements from cell nuclei in breast tissue samples, and the goal is to classify tumors as **malignant** or **benign**.\n",
    "\n",
    "**Sources:**\n",
    "\n",
    "- [sklearn.datasets.load_breast_cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)\n",
    "- [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n",
    "\n",
    "We'll work through a complete machine learning workflow:\n",
    "\n",
    "1. Exploratory Data Analysis (EDA)\n",
    "2. Train/test split\n",
    "3. Baseline model\n",
    "4. \"Kitchen sink\" model (all features, no preprocessing)\n",
    "5. Build your own pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18989855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "df_cancer = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df_cancer[\"target\"] = cancer.target\n",
    "\n",
    "print(f\"Dataset shape: {df_cancer.shape}\")\n",
    "print(f\"Target classes: {cancer.target_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc8c8c",
   "metadata": {},
   "source": [
    "### Task 2.1 Exploratory Data Analysis (EDA)\n",
    "\n",
    "- Task: Conduct an EDA of the breast cancer dataset. For each analysis you perform, explain _why_ you chose to look at it and what it tells you.\n",
    "- Points: 30\n",
    "- Expectations: A mix of code, plots, and written commentary. Quality of reasoning and plots matters more than quantity of plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba63681",
   "metadata": {},
   "source": [
    "From the first five rows, we can see that the dataset contains numeric values for all features, and that the target column has been added correctly. This gives us an initial sense of the data, but we cannot yet confirm the data types or whether there are missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b4929",
   "metadata": {},
   "source": [
    "Next, we use info() to check data types and missing values. This is a nice step to do because it informs us whether preprocessing steps like imputation or type conversion are required before modeling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9826ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71edc9e",
   "metadata": {},
   "source": [
    "From the info() output, we can confirm that all feature columns are numeric (float64), the target column is an integer type (int64), and there are no missing values. This means the dataset is clean and no immediate data cleaning is necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf67805",
   "metadata": {},
   "source": [
    "We then examine the class distribution using value_counts() to assess potential imbalance. Class imbalance can affect the baseline accuracy and the choice of evaluation metrics, as models can become biased toward the majority class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f29e4f0",
   "metadata": {},
   "source": [
    "The output shows that benign tumors are more common than malignant tumors, indicating a moderate class imbalance. This suggests that accuracy alone may be misleading, and we should use relative comparisons to ensure we avoid any bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09dd179",
   "metadata": {},
   "source": [
    "Next, we inspect the feature scales and spread using descriptive statistics. This step is important because many machine learning models are sensitive to the magnitude of input features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39729ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer.drop(columns=\"target\").describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e892276",
   "metadata": {},
   "source": [
    "The summary reveals that some features have values close to zero while others reach the hundreds or thousands. This confirms the need for standardization before applying models that are scale-sensitive, such as logistic regression, SVMs, or PCA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143d351a",
   "metadata": {},
   "source": [
    "To identify which features are most informative for separating malignant and benign tumors, we compute the correlation of each feature with the target:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a306c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_corr = (\n",
    "    df_cancer.corr()[\"target\"].drop(\"target\").abs().sort_values(ascending=False)\n",
    ")\n",
    "fig = px.bar(\n",
    "    target_corr,\n",
    "    title=\"Absolute Correlation of Features with Target\",\n",
    "    labels={\"index\": \"Feature\", \"value\": \"Absolute Correlation\"},\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ef551",
   "metadata": {},
   "source": [
    "This shows which features are most strongly associated with the target. However, some of the top-correlated features might be highly correlated with each other, which would introduce redundancy if plotted all together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea341c",
   "metadata": {},
   "source": [
    "To select a small set of diverse, informative features, we calculate the feature-feature correlation matrix and iteratively pick top target-correlated features while avoiding those that are highly correlated with already-selected features (threshold > 0.9):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d06252",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_corr = df_cancer.drop(columns=\"target\").corr().abs()\n",
    "\n",
    "top_features = []\n",
    "threshold = 0.9\n",
    "sorted_features = target_corr.index.tolist()\n",
    "\n",
    "for feature in sorted_features:\n",
    "    if all(feature_corr[feature][f] < threshold for f in top_features):\n",
    "        top_features.append(feature)\n",
    "    if len(top_features) >= 3:\n",
    "        break\n",
    "\n",
    "print(\"Selected features for distribution plots:\", top_features)\n",
    "for feature in top_features:\n",
    "    fig = px.box(\n",
    "        df_cancer,\n",
    "        x=\"target\",\n",
    "        y=feature,\n",
    "        points=\"all\",\n",
    "        title=f\"{feature} Distribution by Target (0 = Malignant, 1 = Benign)\",\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    df_cancer,\n",
    "    x=top_features[0],\n",
    "    y=top_features[1],\n",
    "    z=top_features[2],\n",
    "    color=\"target\",\n",
    "    title=f\"3D Scatter of Top Features by Target\",\n",
    "    labels={\"target\": \"Target\"},\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.7))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbf06ea",
   "metadata": {},
   "source": [
    "This ensures that the features we visualize are both highly informative for the target and non-redundant, providing the clearest insights for class separation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cc7be",
   "metadata": {},
   "source": [
    "We now visualize the class-conditional distributions of the selected features using histograms:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37157a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in top_features:\n",
    "    fig = px.histogram(\n",
    "        df_cancer,\n",
    "        x=feature,\n",
    "        color=\"target\",\n",
    "        barmode=\"overlay\",\n",
    "        opacity=0.6,\n",
    "        title=f\"Distribution of {feature} by Target (0 = Malignant, 1 = Benign)\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc7d22",
   "metadata": {},
   "source": [
    "From these plots, we observe that malignant tumors generally have larger values in these features, though some overlap exists. This indicates that these features are useful for classification, but the overlap shows that a simple threshold may not perfectly separate the classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8159adba",
   "metadata": {},
   "source": [
    "Finally, we examine the correlations among all features using a heatmap to understand redundancy and relationships:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed866db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df_cancer.corr(), annot=False, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36296d56",
   "metadata": {},
   "source": [
    "The heatmap highlights strong correlations among related features, particularly among measurements of radius, perimeter, and area. This explains why we selected only a subset of features for the distribution plots and suggests that dimensionality reduction (PCA) or regularized models could be useful in downstream analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd0ec0",
   "metadata": {},
   "source": [
    "### Task 2.2 Train/Test Split\n",
    "\n",
    "- Task: Split the data into training and test sets (80/20) before any modeling.\n",
    "- Points: 5\n",
    "- Expectations: Complete the TODO line to create an 80/20 split with `random_state=42` for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_cancer.drop(\"target\", axis=1)\n",
    "y = df_cancer[\"target\"]\n",
    "\n",
    "# TODO: Split into train/test sets. Done\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e8002",
   "metadata": {},
   "source": [
    "### Task 2.3 Baseline Model\n",
    "\n",
    "Before building a real model, it's wise to establish a **baseline** — a classifier that any real model should beat.\n",
    "\n",
    "A **confusion matrix** shows how predictions compare to actual labels:\n",
    "\n",
    "|                     | Predicted Negative  | Predicted Positive  |\n",
    "| ------------------- | ------------------- | ------------------- |\n",
    "| **Actual Negative** | TN (True Negative)  | FP (False Positive) |\n",
    "| **Actual Positive** | FN (False Negative) | TP (True Positive)  |\n",
    "\n",
    "For cancer diagnosis: FN means missing a malignant tumor (bad!), FP means a false alarm (less bad, but still costly).\n",
    "\n",
    "- Task: Run the code below, note the accuracy and examine the confusion matrix. Describe what this classifier does. Would you trust it for diagnosis? Why or why not?\n",
    "- Points: 5\n",
    "- Expectations: A written response (1 paragraph).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338381cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1308362",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "baseline_accuracy = dummy.score(X_test, y_test)\n",
    "print(f\"Baseline accuracy: {baseline_accuracy:.3f}\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    dummy, X_test, y_test, display_labels=cancer.target_names, cmap=\"Blues\"\n",
    ")\n",
    "plt.title(\"Confusion Matrix: Baseline Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556423c",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68097120",
   "metadata": {},
   "source": [
    "Markdown accuracy is 62,3% which by itself would disqualify this model from being used in diagnosis of cancer in patients since its lower than the average for clinical professionals (https://pmc.ncbi.nlm.nih.gov/articles/PMC12047852/). The model uses whatever the highest true label is and categorizes all other predictions in the same category, predicted label: benign since true label: benign is most likely. This is quite frankly an idiotic way of doing it, since in this data set you are guaranteed to get FN's which is verry bad, or the other way around. People who don't actually have cancer get diagnosed with it in 100% of cases where they don't. The way it classifies cases doesn't allow it to change the guesses it makes unless the true label: malignant > true label: benign, which is highly unlikely to happen. This also disqualifies this model from being used. In short I wouldn't trust it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b26210",
   "metadata": {},
   "source": [
    "### Task 2.4 Kitchen Sink Model\n",
    "\n",
    "The \"kitchen sink\" approach: throw all features into the model without any preprocessing. Let's see what happens.\n",
    "\n",
    "**Logistic Regression** is a linear classifier that predicts the probability of a binary outcome. It models:\n",
    "\n",
    "$$P(y=1 | \\mathbf{x}) = \\sigma(\\mathbf{w}^T \\mathbf{x} + b) = \\frac{1}{1 + e^{-(\\mathbf{w}^T \\mathbf{x} + b)}}$$\n",
    "\n",
    "where $\\sigma$ is the sigmoid function, $\\mathbf{w}$ are the feature weights, and $b$ is the bias. The model is trained by minimizing the logistic loss using an iterative optimizer. Here we use **SAGA** (`solver=\"saga\"`), a stochastic gradient method whose fast convergence is only guaranteed on features with approximately the same scale ([sklearn docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)).\n",
    "\n",
    "- Task: Run the code below. Did the model converge? Why or why not? Explain based on your EDA findings and how gradient-based optimization works.\n",
    "- Points: 10\n",
    "- Expectations: A written response (1 paragraph).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e5757c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kitchen sink train accuracy: 0.899\n",
      "Kitchen sink test accuracy:  0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbohmer/IntroKI/course-materials/.venv/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_kitchen = LogisticRegression(solver=\"saga\", max_iter=100, random_state=42)\n",
    "lr_kitchen.fit(X_train, y_train)\n",
    "\n",
    "kitchen_train_accuracy = lr_kitchen.score(X_train, y_train)\n",
    "kitchen_accuracy = lr_kitchen.score(X_test, y_test)\n",
    "print(f\"Kitchen sink train accuracy: {kitchen_train_accuracy:.3f}\")\n",
    "print(f\"Kitchen sink test accuracy:  {kitchen_accuracy:.3f}\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    lr_kitchen, X_test, y_test, display_labels=cancer.target_names, cmap=\"Blues\"\n",
    ")\n",
    "plt.title(\"Confusion Matrix: Kitchen Sink Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9f415a",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "The model did not converge as it hit the upper limit posed by max_iter. Since gradience-based optimisation works by taking small steps based on the \"evenness\" of it's slope to get to the bottom of the slope, if it has too few steps, too short steps, or too big steps it will not converge on the local optimal solution. Doing some brute force testing it needs max_iter at about 3825. But more importantly in the EDA we found out that there were significant divergencies in the scale of some features. As the model used requires aproximately equal scale, this is most probably undermining the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f999713",
   "metadata": {},
   "source": [
    "### Task 2.5 Build Your Own Pipeline\n",
    "\n",
    "Now it's your turn. Based on your EDA findings, build a classification pipeline.\n",
    "\n",
    "A **Pipeline** chains multiple preprocessing steps and a final estimator into a single object. This ensures:\n",
    "\n",
    "- No data leakage (preprocessing is fit only on training data)\n",
    "- Clean, reproducible code\n",
    "- Easy experimentation with different configurations\n",
    "\n",
    "Example pipeline structure:\n",
    "\n",
    "```python\n",
    "Pipeline([\n",
    "    (\"step1_name\", SomeTransformer()),\n",
    "    (\"step2_name\", AnotherTransformer()),\n",
    "    (\"classifier\", SomeClassifier()),\n",
    "])\n",
    "```\n",
    "\n",
    "- Task: Build a pipeline that preprocesses the data and fits a classifier. Evaluate your model, compare it to the kitchen sink model, and justify your preprocessing choices based on your EDA insights.\n",
    "- Points: 20\n",
    "- Notes:\n",
    "  - You are free to use any preprocessing technique (e.g., StandardScaler, PCA, column selection via ColumnTransformer, or others)\n",
    "  - There is no single \"correct\" answer — the goal is thoughtful justification\n",
    "- Expectations:\n",
    "  - A working pipeline with at least one preprocessing step\n",
    "  - A confusion matrix plot for your model\n",
    "  - A comparison with the kitchen sink model's confusion matrix\n",
    "  - A reflection on your model's errors — consider which types of mistakes matter most in a medical diagnosis context (1 paragraph)\n",
    "  - A brief explanation of why you chose your preprocessing steps (1 paragraph)\n",
    "  - **NOTE:** Your understanding and evaluation of the model performance is the objective here. The model's performance (how well it accurately classifies the data) will not detract from your grade. So if your model doesn't perform well, but you can explain why it doesn't perform well, then you can still receive the full 20 points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6405ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build your pipeline\n",
    "# Consider: What preprocessing steps would help based on your EDA?\n",
    "# Available transformers: StandardScaler, PCA, ColumnTransformer, etc.\n",
    "\n",
    "# --- Pipeline model (Scaler + PCA + Logistic Regression) ---\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=10, random_state=42)),\n",
    "        (\"clf\", LogisticRegression(solver=\"saga\", max_iter=3000, random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "### TODO: Fit the pipeline on training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "### TODO: Evaluate and print accuracy\n",
    "pipe_train_accuracy = pipe.score(X_train, y_train)\n",
    "pipe_test_accuracy = pipe.score(X_test, y_test)\n",
    "\n",
    "print(f\"Pipeline train accuracy: {pipe_train_accuracy:.3f}\")\n",
    "print(f\"Pipeline test accuracy:  {pipe_test_accuracy:.3f}\")\n",
    "\n",
    "\n",
    "### TODO: Plot confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe, X_test, y_test, display_labels=cancer.target_names, cmap=\"Greens\"\n",
    ")\n",
    "plt.title(\"Confusion Matrix: Pipeline Model (Scaler + PCA + LR)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022148d6",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "The preprocessing steps used in the pipeline consisted of feature scaling using `StandardScaler` and dimensionality reduction using PCA. `StandardScaler` was applied to ensure that all features contributed equally to the model, while PCA was used to reduce redundancy among highly correlated features prior to fitting the logistic regression classifier.\n",
    "\n",
    "PCA was configured to retain 10 components in order to reduce dimensionality while preserving most of the variance in the original feature space. Based on the EDA, several features exhibited strong correlations, indicating redundancy in the dataset. Reducing the feature space to 10 principal components allows the model to capture the most informative structure in the data while mitigating noise and multicollinearity, resulting in a more stable logistic regression model.\n",
    "\n",
    "All preprocessing steps were implemented within a scikit-learn Pipeline to prevent data leakage. By fitting the scaler and PCA exclusively on the training data and subsequently applying the learned transformations to the test data, the evaluation more accurately reflects how the model would perform on unseen patients. This ensures that no information from the test set influences either preprocessing or model training.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ing3513",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
