{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "812d8092",
   "metadata": {},
   "source": [
    "# Lab 03: Regression Fundamentals\n",
    "\n",
    "**ING3513 - Introduction to Artificial Intelligence and Machine Learning**\n",
    "\n",
    "In this lab, you'll learn the core concepts of regression â€” fitting curves to data and understanding when those fits can go wrong.\n",
    "\n",
    "**What you'll learn:**\n",
    "\n",
    "- Polynomial fitting with NumPy\n",
    "- Mean Squared Error (MSE) as a loss function\n",
    "- Train/test splits for honest evaluation\n",
    "- Overfitting â€” why \"better\" training performance can be worse\n",
    "- The importance of skepticism in ML results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a562e3",
   "metadata": {},
   "source": [
    "## Background: Polynomials and Polynomial Fitting\n",
    "\n",
    "### What is a polynomial?\n",
    "\n",
    "A **polynomial** is a mathematical expression with terms of the form $ax^n$, where $a$ is a coefficient and $n$ is a non-negative integer (the degree of that term).\n",
    "\n",
    "Examples:\n",
    "\n",
    "- **Degree 1 (linear):** $y = 2x + 1$ â€” a straight line\n",
    "- **Degree 2 (quadratic):** $y = x^2 - 2x + 1$ â€” a parabola\n",
    "- **Degree 3 (cubic):** $y = x^3 - 3x$ â€” an S-shaped curve\n",
    "\n",
    "The **degree** of a polynomial is the highest power of $x$. Higher-degree polynomials can represent more complex, \"wiggly\" curves.\n",
    "\n",
    "### What is polynomial fitting?\n",
    "\n",
    "**Polynomial fitting** (or polynomial regression) finds the polynomial that best matches a set of data points. Given data, we choose a degree $d$ and find coefficients $a_0, a_1, \\ldots, a_d$ such that:\n",
    "\n",
    "$$y = a_0 + a_1 x + a_2 x^2 + \\cdots + a_d x^d$$\n",
    "\n",
    "The \"best\" fit minimizes the total error between the polynomial's predictions and the actual data points.\n",
    "\n",
    "### Why does this matter for ML?\n",
    "\n",
    "Polynomial fitting is a simple example of **model selection** â€” choosing the right complexity for your model. It illustrates a fundamental tension in machine learning:\n",
    "\n",
    "- Too simple (low degree) â†’ **underfitting** â€” can't capture the pattern\n",
    "- Too complex (high degree) â†’ **overfitting** â€” captures noise instead of pattern\n",
    "\n",
    "This lab uses polynomials to build intuition for these concepts, which apply to ALL machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2d20fc",
   "metadata": {},
   "source": [
    "## 1. The Scenario â€” Fitting Curves to Data\n",
    "\n",
    "Imagine you've collected measurements and want to discover the underlying pattern. This is the essence of regression: given noisy data, find a function that describes it.\n",
    "\n",
    "Let's start with a simple example â€” data generated from a quadratic function with some noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2656d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data from a quadratic function: y = xÂ² - 2x + 1 = (x-1)Â²\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.linspace(-3, 3, 40).reshape(\n",
    "    -1, 1\n",
    ")  # sklearn requires 2D: (n_samples, n_features)\n",
    "y_true = X.flatten() ** 2 - 2 * X.flatten() + 1  # True underlying function\n",
    "y = y_true + np.random.normal(0, 1.0, size=y_true.shape)  # Add noise (Ïƒ=1.0)\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X.flatten(), y=y, s=80, alpha=0.7, label=\"Observed data\")\n",
    "sns.lineplot(\n",
    "    x=X.flatten(),\n",
    "    y=y_true,\n",
    "    color=\"green\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"True function: $(x-1)^2$\",\n",
    ")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Our Data: Quadratic Function + Noise (Ïƒ = 1.0)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of data points: {len(X)}\")\n",
    "print(f\"X shape: {X.shape} â€” Note: sklearn needs 2D arrays (samples Ã— features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32687d5b",
   "metadata": {},
   "source": [
    "## 2. Polynomial Fitting with sklearn\n",
    "\n",
    "sklearn uses a **Pipeline** that combines:\n",
    "\n",
    "1. **`PolynomialFeatures`** â€” transforms X into [1, X, XÂ², XÂ³, ...]\n",
    "2. **`LinearRegression`** â€” fits coefficients to minimize squared error\n",
    "\n",
    "This pattern (`fit()` then `predict()`) is the same for ALL sklearn models!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0006a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a polynomial regression model (degree 2)\n",
    "model = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False), LinearRegression()\n",
    ")\n",
    "\n",
    "# Fit the model to our data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the coefficients\n",
    "poly_features = model.named_steps[\"polynomialfeatures\"]\n",
    "lin_reg = model.named_steps[\"linearregression\"]\n",
    "print(f\"Intercept: {lin_reg.intercept_:.4f}\")\n",
    "print(f\"Coefficients: {lin_reg.coef_}\")\n",
    "print(\"True coefficients: intercept=1, coef=[-2, 1] for (x-1)Â²\")\n",
    "\n",
    "# Generate predictions for smooth plotting\n",
    "X_smooth = np.linspace(-3, 3, 200).reshape(-1, 1)\n",
    "y_fitted = model.predict(X_smooth)\n",
    "y_true_smooth = X_smooth.flatten() ** 2 - 2 * X_smooth.flatten() + 1\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X.flatten(), y=y, s=80, alpha=0.7, label=\"Observed data\")\n",
    "sns.lineplot(\n",
    "    x=X_smooth.flatten(),\n",
    "    y=y_true_smooth,\n",
    "    color=\"green\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"True function: $(x-1)^2$\",\n",
    ")\n",
    "sns.lineplot(\n",
    "    x=X_smooth.flatten(),\n",
    "    y=y_fitted,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    label=\"Fitted polynomial (deg 2)\",\n",
    ")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Polynomial Fit to Data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269cb691",
   "metadata": {},
   "source": [
    "## 3. Mean Squared Error (MSE)\n",
    "\n",
    "How do we measure how good our fit is? The **Mean Squared Error** is the average of squared differences between predicted and actual values:\n",
    "\n",
    "$$MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "where $y_i$ is the actual value and $\\hat{y}_i$ is the predicted value.\n",
    "\n",
    "**Why squared?**\n",
    "\n",
    "- Penalizes large errors more than small ones\n",
    "- Always positive (no cancellation of positive/negative errors)\n",
    "- Mathematically convenient for optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MSE using sklearn's function\n",
    "y_pred = model.predict(X)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(\n",
    "    f\"\\nInterpretation: On average, our predictions are off by âˆš{mse:.4f} â‰ˆ {np.sqrt(mse):.2f}\"\n",
    ")\n",
    "\n",
    "# Note: sklearn also provides RÂ² score (coefficient of determination)\n",
    "r2 = model.score(X, y)  # Built-in method returns RÂ²\n",
    "print(f\"RÂ² score: {r2:.4f} (1.0 = perfect fit, 0.0 = predicts mean)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cac6e7",
   "metadata": {},
   "source": [
    "## 4. The Problem â€” What If We Fit the Wrong Degree?\n",
    "\n",
    "What happens if we use the wrong polynomial degree? Let's try:\n",
    "\n",
    "- **Degree 1** (linear) â€” too simple?\n",
    "- **Degree 2** (quadratic) â€” just right?\n",
    "- **Degree 9** (high-order) â€” too complex?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd1c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit polynomials of different degrees\n",
    "degrees = [1, 2, 9]\n",
    "models = {}\n",
    "\n",
    "for deg in degrees:\n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(degree=deg, include_bias=False), LinearRegression()\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    models[deg] = model\n",
    "\n",
    "# Visualize all three fits\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "titles = [\"Degree 1 (Underfit?)\", \"Degree 2 (Good Fit?)\", \"Degree 9 (Overfit?)\"]\n",
    "y_true_smooth = X_smooth.flatten() ** 2 - 2 * X_smooth.flatten() + 1\n",
    "\n",
    "for ax, deg, title in zip(axes, degrees, titles):\n",
    "    y_pred = models[deg].predict(X_smooth)\n",
    "    mse = mean_squared_error(y, models[deg].predict(X))\n",
    "\n",
    "    sns.scatterplot(x=X.flatten(), y=y, s=60, alpha=0.7, ax=ax)\n",
    "    ax.plot(X_smooth.flatten(), y_true_smooth, \"g--\", alpha=0.6, label=\"True function\")\n",
    "    sns.lineplot(\n",
    "        x=X_smooth.flatten(),\n",
    "        y=y_pred,\n",
    "        color=\"red\",\n",
    "        linewidth=2,\n",
    "        ax=ax,\n",
    "        label=f\"Fit (deg {deg})\",\n",
    "    )\n",
    "    ax.set_title(f\"{title}\\nMSE = {mse:.4f}\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_ylim(-2, 18)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print MSE comparison\n",
    "print(\"MSE Comparison:\")\n",
    "for deg in degrees:\n",
    "    mse = mean_squared_error(y, models[deg].predict(X))\n",
    "    print(f\"  Degree {deg}: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafa06b",
   "metadata": {},
   "source": [
    "### Wait... Degree 9 has the _lowest_ MSE!\n",
    "\n",
    "The degree-9 polynomial fits our data points better than the true degree-2 polynomial. Does that mean we should use degree 9?\n",
    "\n",
    "**No!** This is a critical lesson: the degree-9 polynomial is fitting the _noise_, not the underlying pattern. It will perform terribly on new data.\n",
    "\n",
    "But how can we detect this problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431bbb08",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split â€” The Solution\n",
    "\n",
    "The solution is to **hide some data** during training. We only use part of our data to fit the model, then evaluate on the hidden portion.\n",
    "\n",
    "- **Training set**: Used to fit the polynomial\n",
    "- **Test set**: Hidden during fitting, used for honest evaluation\n",
    "\n",
    "If a model has low training error but high test error, it's **overfitting** â€” memorizing the training data rather than learning the pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28059a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 70% training, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "# Visualize the split\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    x=X_train.flatten(), y=y_train, s=80, label=f\"Training data ({len(X_train)} points)\"\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=X_test.flatten(),\n",
    "    y=y_test,\n",
    "    s=80,\n",
    "    marker=\"s\",\n",
    "    label=f\"Test data ({len(X_test)} points)\",\n",
    ")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Train/Test Split\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit using ONLY training data and evaluate on BOTH sets\n",
    "degrees = [1, 2, 9]\n",
    "\n",
    "print(\"Degree | Train MSE | Test MSE\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for deg in degrees:\n",
    "    # Create and fit model on training data only\n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(degree=deg, include_bias=False), LinearRegression()\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Compute MSE on both sets\n",
    "    train_mse = mean_squared_error(y_train, model.predict(X_train))\n",
    "    test_mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "\n",
    "    print(f\"  {deg:4d}  |  {train_mse:7.4f}  |  {test_mse:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0c8a0e",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Now the truth is revealed!\n",
    "\n",
    "Degree 9 has the lowest _training_ MSE, but look at its _test_ MSE â€” it's worse than degree 2!\n",
    "\n",
    "This is **overfitting**: the model fits the training data too well, including the noise, so it fails to generalize to new data. Notice also the _gap_ between train and test MSE for degree 9 â€” that gap is the telltale sign.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb9ee1",
   "metadata": {},
   "source": [
    "## 6. Helper Functions for Experiments\n",
    "\n",
    "Before we dive into larger experiments, let's define some helper functions to generate data and run fits systematically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46759ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our \"true\" polynomial coefficients (for data generation only)\n",
    "# Format: [coef for x^n, ..., coef for x^1, coef for x^0]\n",
    "TRUE_POLY_COEFFS = {\n",
    "    1: [2, 1],  # y = 2x + 1\n",
    "    2: [1, -2, 1],  # y = xÂ² - 2x + 1 = (x-1)Â²\n",
    "    3: [0.5, 0, -2, 0],  # y = 0.5xÂ³ - 2x\n",
    "}\n",
    "\n",
    "\n",
    "def generate_polynomial_data(\n",
    "    degree, n_points=40, noise_std=0.5, x_range=(-3, 3), seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate data from a true polynomial with added Gaussian noise.\n",
    "\n",
    "    Parameters:\n",
    "    - degree: Which true polynomial to use (1, 2, or 3)\n",
    "    - n_points: Number of data points\n",
    "    - noise_std: Standard deviation of Gaussian noise\n",
    "    - x_range: Tuple of (min_x, max_x)\n",
    "    - seed: Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - X: Input values (2D array for sklearn)\n",
    "    - y: Output values (with noise)\n",
    "    - y_true: True output values (without noise)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    X = np.linspace(x_range[0], x_range[1], n_points).reshape(-1, 1)\n",
    "    poly = np.poly1d(TRUE_POLY_COEFFS[degree])\n",
    "    y_true = poly(X.flatten())\n",
    "    y = y_true + np.random.normal(0, noise_std, size=y_true.shape)\n",
    "\n",
    "    return X, y, y_true\n",
    "\n",
    "\n",
    "def fit_and_evaluate(X_train, y_train, X_test, y_test, fit_degree):\n",
    "    \"\"\"\n",
    "    Fit a polynomial model and return train/test MSE.\n",
    "\n",
    "    Returns:\n",
    "    - model: The fitted sklearn pipeline\n",
    "    - train_mse: MSE on training data\n",
    "    - test_mse: MSE on test data\n",
    "    \"\"\"\n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(degree=fit_degree, include_bias=False), LinearRegression()\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, model.predict(X_train))\n",
    "    test_mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "\n",
    "    return model, train_mse, test_mse\n",
    "\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514af8a",
   "metadata": {},
   "source": [
    "## 7. Generating Multiple Datasets\n",
    "\n",
    "Let's create datasets from polynomials of different degrees, each with the same small amount of noise. This lets us see what \"ideal\" data looks like for each underlying function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d9928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate datasets from degree 1, 2, and 3 polynomials\n",
    "data_degrees = [1, 2, 3]\n",
    "datasets = {}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, deg in zip(axes, data_degrees):\n",
    "    X_data, y_data, y_true = generate_polynomial_data(deg, noise_std=1.0, seed=42 + deg)\n",
    "    datasets[deg] = (X_data, y_data, y_true)\n",
    "\n",
    "    # Plot\n",
    "    sns.scatterplot(\n",
    "        x=X_data.flatten(), y=y_data, s=60, alpha=0.7, ax=ax, label=\"Noisy data\"\n",
    "    )\n",
    "    X_smooth = np.linspace(-3, 3, 200)\n",
    "    y_smooth = np.poly1d(TRUE_POLY_COEFFS[deg])(X_smooth)\n",
    "    sns.lineplot(\n",
    "        x=X_smooth,\n",
    "        y=y_smooth,\n",
    "        color=\"green\",\n",
    "        linestyle=\"--\",\n",
    "        ax=ax,\n",
    "        label=\"True function\",\n",
    "    )\n",
    "    ax.set_title(f\"Data from Degree-{deg} Polynomial\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Datasets generated from polynomials of degree 1, 2, and 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2060bd0",
   "metadata": {},
   "source": [
    "## 8. The Fitting Matrix\n",
    "\n",
    "Now let's systematically explore what happens when we fit different polynomial degrees to different datasets.\n",
    "\n",
    "We'll fit all combinations:\n",
    "\n",
    "- Data generated from degrees: 1, 2, 3\n",
    "- Fitting polynomial degrees: 1, 2, 3, 9\n",
    "\n",
    "This gives us a 3Ã—4 matrix of results. For each combination, we compute both train MSE and test MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3635160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "data_degrees = [1, 2, 3]  # Degrees used to generate the data\n",
    "fit_degrees = [1, 2, 3, 9]  # Degrees we'll try to fit\n",
    "noise_std = 1.0  # Same as initial data generation\n",
    "\n",
    "# Initialize result matrices\n",
    "n_data = len(data_degrees)\n",
    "n_fits = len(fit_degrees)\n",
    "train_mse_matrix = np.zeros((n_data, n_fits))\n",
    "test_mse_matrix = np.zeros((n_data, n_fits))\n",
    "\n",
    "# Run all combinations\n",
    "for i, data_deg in enumerate(data_degrees):\n",
    "    # Generate data for this source polynomial\n",
    "    X_data, y_data, _ = generate_polynomial_data(\n",
    "        data_deg, noise_std=noise_std, seed=42 + data_deg\n",
    "    )\n",
    "\n",
    "    # Split into train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_data, y_data, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    for j, fit_deg in enumerate(fit_degrees):\n",
    "        # Fit and evaluate\n",
    "        _, train_mse, test_mse = fit_and_evaluate(\n",
    "            X_train, y_train, X_test, y_test, fit_deg\n",
    "        )\n",
    "\n",
    "        train_mse_matrix[i, j] = train_mse\n",
    "        test_mse_matrix[i, j] = test_mse\n",
    "\n",
    "print(\"Fitting complete! Results stored in train_mse_matrix and test_mse_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5857cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results as heatmaps\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training MSE heatmap\n",
    "sns.heatmap(\n",
    "    train_mse_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".3f\",\n",
    "    xticklabels=[f\"Fit deg {d}\" for d in fit_degrees],\n",
    "    yticklabels=[f\"Data deg {d}\" for d in data_degrees],\n",
    "    cmap=\"YlOrRd\",\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[0].set_title(\"Training MSE\\n(Lower = Better Fit to Training Data)\")\n",
    "axes[0].set_xlabel(\"Fitting Polynomial Degree\")\n",
    "axes[0].set_ylabel(\"Data Generated From Degree\")\n",
    "\n",
    "# Test MSE heatmap\n",
    "sns.heatmap(\n",
    "    test_mse_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".3f\",\n",
    "    xticklabels=[f\"Fit deg {d}\" for d in fit_degrees],\n",
    "    yticklabels=[f\"Data deg {d}\" for d in data_degrees],\n",
    "    cmap=\"YlOrRd\",\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title(\"Test MSE\\n(Lower = Better Generalization)\")\n",
    "axes[1].set_xlabel(\"Fitting Polynomial Degree\")\n",
    "axes[1].set_ylabel(\"Data Generated From Degree\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d0c2e2",
   "metadata": {},
   "source": [
    "### Observations from the Fitting Matrix\n",
    "\n",
    "**Look at the Training MSE (left):**\n",
    "\n",
    "- Degree 9 almost always has the lowest training MSE\n",
    "- Higher-degree polynomials can always fit training data better (or at least as well)\n",
    "\n",
    "**Look at the Test MSE (right):**\n",
    "\n",
    "- The best test MSE is typically when fit degree â‰ˆ data degree\n",
    "- Degree 9 often has _worse_ test MSE despite _better_ training MSE\n",
    "\n",
    "**Key insight:** Training MSE alone is misleading! We must always evaluate on held-out test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66dfbaa",
   "metadata": {},
   "source": [
    "## 9. Visualizing Underfit / Good Fit / Overfit\n",
    "\n",
    "Let's visualize three specific cases to build intuition:\n",
    "\n",
    "1. **Underfit**: Degree-1 fit on degree-3 data (too simple)\n",
    "2. **Good fit**: Degree-3 fit on degree-3 data (just right)\n",
    "3. **Overfit**: Degree-9 fit on degree-3 data (too complex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate degree-3 data\n",
    "X_deg3, y_deg3, _ = generate_polynomial_data(3, noise_std=1.0, seed=45)\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(\n",
    "    X_deg3, y_deg3, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Fit different degree polynomials\n",
    "fit_cases = [\n",
    "    (1, \"Underfit\", \"steelblue\"),\n",
    "    (3, \"Good Fit\", \"green\"),\n",
    "    (9, \"Overfit\", \"red\"),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "X_smooth = np.linspace(-3, 3, 200).reshape(-1, 1)\n",
    "\n",
    "for ax, (fit_deg, title, color) in zip(axes, fit_cases):\n",
    "    model, train_mse, test_mse = fit_and_evaluate(\n",
    "        X_train_3, y_train_3, X_test_3, y_test_3, fit_deg\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    sns.scatterplot(\n",
    "        x=X_train_3.flatten(), y=y_train_3, s=60, alpha=0.7, ax=ax, label=\"Train\"\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=X_test_3.flatten(),\n",
    "        y=y_test_3,\n",
    "        s=60,\n",
    "        marker=\"s\",\n",
    "        alpha=0.7,\n",
    "        ax=ax,\n",
    "        label=\"Test\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        X_smooth.flatten(),\n",
    "        model.predict(X_smooth),\n",
    "        color=color,\n",
    "        linewidth=2,\n",
    "        label=f\"Fit (deg {fit_deg})\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        X_smooth.flatten(),\n",
    "        np.poly1d(TRUE_POLY_COEFFS[3])(X_smooth.flatten()),\n",
    "        \"k--\",\n",
    "        alpha=0.5,\n",
    "        label=\"True function\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"{title} (Degree {fit_deg})\\nTrain MSE: {train_mse:.3f} | Test MSE: {test_mse:.3f}\"\n",
    "    )\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_ylim(-8, 8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0eeb8",
   "metadata": {},
   "source": [
    "## 10. The Effect of Noise\n",
    "\n",
    "What happens as data gets noisier? Let's run our fitting experiment across different noise levels.\n",
    "\n",
    "**Hypothesis:** With more noise, high-degree polynomials will:\n",
    "\n",
    "- Have even lower training MSE (they fit noise better!)\n",
    "- Have much higher test MSE (they generalize worse!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6699f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise experiment configuration\n",
    "noise_levels = [0.3, 0.5, 1.0, 2.0, 4.0]\n",
    "data_deg = 2  # Focus on degree-2 data\n",
    "fit_degrees = [1, 2, 3, 9]\n",
    "\n",
    "# Store results for each noise level\n",
    "results = {noise: {\"train\": [], \"test\": []} for noise in noise_levels}\n",
    "\n",
    "for noise_std in noise_levels:\n",
    "    # Generate data with this noise level\n",
    "    X_data, y_data, _ = generate_polynomial_data(data_deg, noise_std=noise_std, seed=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_data, y_data, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    for fit_deg in fit_degrees:\n",
    "        _, train_mse, test_mse = fit_and_evaluate(\n",
    "            X_train, y_train, X_test, y_test, fit_deg\n",
    "        )\n",
    "        results[noise_std][\"train\"].append(train_mse)\n",
    "        results[noise_std][\"test\"].append(test_mse)\n",
    "\n",
    "print(\"Noise experiment complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how data looks at different noise levels\n",
    "fig, axes = plt.subplots(1, 5, figsize=(18, 4))\n",
    "\n",
    "for ax, noise_std in zip(axes, noise_levels):\n",
    "    X_data, y_data, y_true = generate_polynomial_data(\n",
    "        data_deg, noise_std=noise_std, seed=42\n",
    "    )\n",
    "\n",
    "    sns.scatterplot(x=X_data.flatten(), y=y_data, s=50, alpha=0.7, ax=ax)\n",
    "    ax.plot(\n",
    "        np.linspace(-3, 3, 100),\n",
    "        np.poly1d(TRUE_POLY_COEFFS[data_deg])(np.linspace(-3, 3, 100)),\n",
    "        \"g--\",\n",
    "        alpha=0.7,\n",
    "        label=\"True\",\n",
    "    )\n",
    "    ax.set_title(f\"Noise Ïƒ = {noise_std}\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylim(-15, 25)\n",
    "\n",
    "axes[0].set_ylabel(\"y\")\n",
    "plt.suptitle(\"Degree-2 Data with Increasing Noise\", y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e1c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Train-Test GAP â€” the clearest overfitting signal\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Prepare data for plotting\n",
    "gap_data = {deg: [] for deg in fit_degrees}\n",
    "\n",
    "for noise_std in noise_levels:\n",
    "    for i, deg in enumerate(fit_degrees):\n",
    "        train_mse = results[noise_std][\"train\"][i]\n",
    "        test_mse = results[noise_std][\"test\"][i]\n",
    "        gap_data[deg].append(test_mse - train_mse)\n",
    "\n",
    "# Plot the gap for each polynomial degree\n",
    "colors = [\"steelblue\", \"green\", \"orange\", \"red\"]\n",
    "for deg, color in zip(fit_degrees, colors):\n",
    "    ax.plot(\n",
    "        noise_levels,\n",
    "        gap_data[deg],\n",
    "        \"o-\",\n",
    "        label=f\"Fit deg {deg}\",\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel(\"Noise Level (Ïƒ)\", fontsize=12)\n",
    "ax.set_ylabel(\"Test MSE âˆ’ Train MSE (Gap)\", fontsize=12)\n",
    "ax.set_title(\"The Overfitting Gap: How Much Worse is Test vs Train?\", fontsize=14)\n",
    "ax.legend()\n",
    "ax.axhline(y=0, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"No gap (ideal)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“Š The gap between test and train MSE is the signature of overfitting.\")\n",
    "print(\"   Degree 9 has the largest gap at every noise level â€” it overfits the most!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5889a705",
   "metadata": {},
   "source": [
    "### Key Observations from the Gap Plot\n",
    "\n",
    "**The Train-Test Gap reveals overfitting:**\n",
    "\n",
    "- **Degree 2** (the correct model) has a gap near zero at all noise levels â€” train and test performance match\n",
    "- **Degree 9** has the largest gap, and it grows with noise â€” clear overfitting!\n",
    "- **Degree 1** (underfit) also has a small gap, but both train AND test are bad\n",
    "\n",
    "**Why the gap matters:**\n",
    "\n",
    "In practice, you won't know the \"true\" function. But you CAN always measure the train-test gap. A large gap is a warning sign that your model is too complex for your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c4465",
   "metadata": {},
   "source": [
    "## 11. The Overfitting Deep Dive\n",
    "\n",
    "Let's visualize exactly what happens when we fit high-degree polynomials to noisy data. The overfit model will look \"wiggly\" as it tries to pass through every noisy data point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare degree-2 vs degree-9 fits at high noise\n",
    "high_noise = 2.0\n",
    "X_data, y_data, _ = generate_polynomial_data(2, noise_std=high_noise, seed=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "X_smooth = np.linspace(-3, 3, 200).reshape(-1, 1)\n",
    "\n",
    "for ax, fit_deg, color, title in zip(\n",
    "    axes,\n",
    "    [2, 9],\n",
    "    [\"green\", \"purple\"],\n",
    "    [\"Degree 2 (Correct Model)\", \"Degree 9 (Overfit)\"],\n",
    "):\n",
    "    model, train_mse, test_mse = fit_and_evaluate(\n",
    "        X_train, y_train, X_test, y_test, fit_deg\n",
    "    )\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=X_train.flatten(), y=y_train, s=80, ax=ax, label=\"Train\", alpha=0.7\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=X_test.flatten(), y=y_test, s=80, marker=\"s\", ax=ax, label=\"Test\", alpha=0.7\n",
    "    )\n",
    "    ax.plot(\n",
    "        X_smooth.flatten(),\n",
    "        model.predict(X_smooth),\n",
    "        color=color,\n",
    "        linewidth=2,\n",
    "        label=f\"Fit (deg {fit_deg})\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        X_smooth.flatten(),\n",
    "        np.poly1d(TRUE_POLY_COEFFS[2])(X_smooth.flatten()),\n",
    "        \"k--\",\n",
    "        alpha=0.5,\n",
    "        label=\"True function\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{title}\\nTrain MSE: {train_mse:.2f} | Test MSE: {test_mse:.2f}\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.legend()\n",
    "    ax.set_ylim(-15, 25)\n",
    "\n",
    "plt.suptitle(f\"High Noise Data (Ïƒ = {high_noise})\", y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ” Notice how the degree-9 polynomial 'wiggles' to fit every training point!\")\n",
    "print(\"   But it completely misses the test points and the true underlying pattern.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09538f87",
   "metadata": {},
   "source": [
    "## 12. The Classic Overfitting Curve\n",
    "\n",
    "This is the most iconic visualization in machine learning: test error forms a **U-shape** as model complexity increases.\n",
    "\n",
    "- **Left side of U:** Underfitting â€” model too simple\n",
    "- **Bottom of U:** Sweet spot â€” right complexity\n",
    "- **Right side of U:** Overfitting â€” model too complex\n",
    "\n",
    "Compare this to neural network training curves where the X-axis is epochs instead of polynomial degree â€” same phenomenon!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66548f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classic overfitting curve: U-shaped test error\n",
    "noise_std = 1.5\n",
    "X_data, y_data, _ = generate_polynomial_data(2, noise_std=noise_std, seed=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Test up to degree 15 to see overfitting continue to worsen\n",
    "degrees_to_test = list(range(1, 16))\n",
    "train_mses = []\n",
    "test_mses = []\n",
    "\n",
    "for deg in degrees_to_test:\n",
    "    _, train_mse, test_mse = fit_and_evaluate(X_train, y_train, X_test, y_test, deg)\n",
    "    train_mses.append(train_mse)\n",
    "    test_mses.append(test_mse)\n",
    "\n",
    "# Create two-panel figure: full scale + zoomed view\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left panel: Full scale (shows dramatic test MSE explosion)\n",
    "ax1 = axes[0]\n",
    "ax1.plot(\n",
    "    degrees_to_test,\n",
    "    train_mses,\n",
    "    \"o-\",\n",
    "    label=\"Train MSE\",\n",
    "    color=\"steelblue\",\n",
    "    linewidth=2,\n",
    "    markersize=7,\n",
    ")\n",
    "ax1.plot(\n",
    "    degrees_to_test,\n",
    "    test_mses,\n",
    "    \"o-\",\n",
    "    label=\"Test MSE\",\n",
    "    color=\"coral\",\n",
    "    linewidth=2,\n",
    "    markersize=7,\n",
    ")\n",
    "\n",
    "best_deg = degrees_to_test[np.argmin(test_mses)]\n",
    "best_test_mse = min(test_mses)\n",
    "ax1.axvline(\n",
    "    x=best_deg,\n",
    "    color=\"green\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.5,\n",
    "    label=f\"Best degree = {best_deg}\",\n",
    ")\n",
    "ax1.scatter([best_deg], [best_test_mse], color=\"green\", s=150, zorder=5, marker=\"*\")\n",
    "\n",
    "ax1.set_xlabel(\"Polynomial Degree\", fontsize=11)\n",
    "ax1.set_ylabel(\"MSE\", fontsize=11)\n",
    "ax1.set_title(\"Full Scale: Test MSE Explodes!\", fontsize=12)\n",
    "ax1.set_xticks(degrees_to_test)\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax1.annotate(\n",
    "    \"Overfitting\\nhas no limit!\",\n",
    "    xy=(15, test_mses[-1]),\n",
    "    xytext=(12, test_mses[-1] * 0.7),\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    "    color=\"red\",\n",
    "    arrowprops=dict(arrowstyle=\"->\", color=\"red\", alpha=0.7),\n",
    ")\n",
    "\n",
    "# Right panel: Zoomed view (shows training MSE decreasing)\n",
    "ax2 = axes[1]\n",
    "ax2.plot(\n",
    "    degrees_to_test,\n",
    "    train_mses,\n",
    "    \"o-\",\n",
    "    label=\"Train MSE\",\n",
    "    color=\"steelblue\",\n",
    "    linewidth=2,\n",
    "    markersize=7,\n",
    ")\n",
    "ax2.plot(\n",
    "    degrees_to_test,\n",
    "    test_mses,\n",
    "    \"o-\",\n",
    "    label=\"Test MSE\",\n",
    "    color=\"coral\",\n",
    "    linewidth=2,\n",
    "    markersize=7,\n",
    ")\n",
    "\n",
    "ax2.axvline(\n",
    "    x=best_deg,\n",
    "    color=\"green\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.5,\n",
    "    label=f\"Best degree = {best_deg}\",\n",
    ")\n",
    "ax2.scatter([best_deg], [best_test_mse], color=\"green\", s=150, zorder=5, marker=\"*\")\n",
    "\n",
    "# Zoom to show training MSE detail\n",
    "ax2.set_ylim(0, 15)  # Zoomed scale\n",
    "ax2.set_xlabel(\"Polynomial Degree\", fontsize=11)\n",
    "ax2.set_ylabel(\"MSE\", fontsize=11)\n",
    "ax2.set_title(\"Zoomed: Training MSE Keeps Dropping\", fontsize=12)\n",
    "ax2.set_xticks(degrees_to_test)\n",
    "ax2.legend(loc=\"upper right\")\n",
    "ax2.annotate(\n",
    "    \"Train MSE\\nâ†“ keeps falling\",\n",
    "    xy=(10, train_mses[9]),\n",
    "    xytext=(7, 6),\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    "    color=\"steelblue\",\n",
    "    arrowprops=dict(arrowstyle=\"->\", color=\"steelblue\", alpha=0.7),\n",
    ")\n",
    "ax2.annotate(\n",
    "    \"Underfitting\",\n",
    "    xy=(1, train_mses[0]),\n",
    "    xytext=(2.5, train_mses[0] + 2),\n",
    "    fontsize=10,\n",
    "    ha=\"center\",\n",
    "    color=\"gray\",\n",
    ")\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"The Classic Overfitting Curve (True function: degree 2, Noise Ïƒ = {noise_std})\",\n",
    "    fontsize=14,\n",
    "    y=1.02,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“ˆ Train MSE keeps decreasing â€” the model fits training data better and better.\")\n",
    "print(\"ðŸ“‰ Test MSE keeps INCREASING â€” overfitting has no limit!\")\n",
    "print(f\"â­ The sweet spot is degree {best_deg} â€” matching the true function.\")\n",
    "print(\n",
    "    f\"\\nðŸ”¥ At degree 15: Train MSE = {train_mses[-1]:.2f}, Test MSE = {test_mses[-1]:.1f}\"\n",
    ")\n",
    "print(\n",
    "    f\"   That's {test_mses[-1] / best_test_mse:.0f}x worse than optimal on test data!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceadd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does degree 15 actually LOOK like? Let's see the wiggly madness!\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "X_smooth = np.linspace(-3, 3, 300).reshape(-1, 1)\n",
    "\n",
    "showcase_degrees = [2, 9, 15]\n",
    "colors = [\"green\", \"orange\", \"red\"]\n",
    "titles = [\"Degree 2 (Correct)\", \"Degree 9 (Overfit)\", \"Degree 15 (Extreme Overfit)\"]\n",
    "\n",
    "for ax, deg, color, title in zip(axes, showcase_degrees, colors, titles):\n",
    "    model, train_mse, test_mse = fit_and_evaluate(X_train, y_train, X_test, y_test, deg)\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=X_train.flatten(), y=y_train, s=70, ax=ax, label=\"Train\", alpha=0.7\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=X_test.flatten(), y=y_test, s=70, marker=\"s\", ax=ax, label=\"Test\", alpha=0.7\n",
    "    )\n",
    "\n",
    "    # Plot the fitted curve\n",
    "    y_pred_smooth = model.predict(X_smooth)\n",
    "    ax.plot(\n",
    "        X_smooth.flatten(),\n",
    "        y_pred_smooth,\n",
    "        color=color,\n",
    "        linewidth=2,\n",
    "        label=f\"Fit (deg {deg})\",\n",
    "    )\n",
    "\n",
    "    # True function\n",
    "    ax.plot(\n",
    "        X_smooth.flatten(),\n",
    "        np.poly1d(TRUE_POLY_COEFFS[2])(X_smooth.flatten()),\n",
    "        \"k--\",\n",
    "        alpha=0.5,\n",
    "        label=\"True function\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{title}\\nTrain MSE: {train_mse:.2f} | Test MSE: {test_mse:.2f}\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_ylim(-10, 20)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle(\"What Overfitting Looks Like: The Wiggly Madness\", y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"ðŸ‘€ As degree increases, the polynomial contorts itself to hit every training point.\"\n",
    ")\n",
    "print(\"   But this 'flexibility' is exactly what destroys generalization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf5cd53",
   "metadata": {},
   "source": [
    "### ðŸŽ“ Bonus: Runge's Phenomenon\n",
    "\n",
    "_Optional reading for curious students!_\n",
    "\n",
    "The wild oscillations you see at the edges of the degree-15 fit have a name: **Runge's phenomenon**, discovered by German mathematician Carl Runge in 1901.\n",
    "\n",
    "**What's happening:** When fitting high-degree polynomials to evenly-spaced points, the polynomial tends to oscillate wildly near the boundaries â€” even if the underlying function is perfectly smooth! The more points and higher the degree, the worse the oscillations become at the edges.\n",
    "\n",
    "**Why it matters:** This isn't just a quirk of polynomials. It's an early example of a general principle: **more flexibility isn't always better**. A model with too many parameters will find ways to fit the training data that have nothing to do with the true underlying pattern.\n",
    "\n",
    "This is exactly the overfitting problem we've been studying â€” Runge just discovered it 100+ years before \"machine learning\" existed!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1032191",
   "metadata": {},
   "source": [
    "## 13. Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Polynomial regression with sklearn** uses `PolynomialFeatures` + `LinearRegression` in a pipeline\n",
    "   - The `fit()` â†’ `predict()` pattern is consistent across all sklearn models\n",
    "\n",
    "2. **Mean Squared Error (MSE)** measures prediction quality\n",
    "   - Lower is better â€” but only when measured correctly!\n",
    "\n",
    "3. **Train/test split** is essential for honest evaluation\n",
    "   - Training error alone is misleading\n",
    "   - Test error estimates real-world performance\n",
    "\n",
    "4. **Overfitting** = model too complex for the data\n",
    "   - Symptom: Low train error, high test error (the \"gap\")\n",
    "   - Cause: Model memorizes noise instead of learning the pattern\n",
    "   - There's no limit â€” degree 15 was 60x worse than optimal!\n",
    "\n",
    "5. **The classic U-shaped curve** appears everywhere in ML\n",
    "   - Too simple â†’ underfitting (high train AND test error)\n",
    "   - Just right â†’ sweet spot (low test error)\n",
    "   - Too complex â†’ overfitting (low train, high test error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e060c",
   "metadata": {},
   "source": [
    "### Reflection Questions\n",
    "\n",
    "Think about and discuss with your classmates:\n",
    "\n",
    "1. **Why does a high-degree polynomial have lower training error even on simple data?**\n",
    "\n",
    "2. **Looking at the degree-15 visualization â€” why does the polynomial go crazy at the edges?**\n",
    "\n",
    "3. **If you only had training data (no test set), how might you be fooled by an overfit model?**\n",
    "\n",
    "4. **In real ML problems, you don't know the \"true\" underlying function. How would you choose the right model complexity?**\n",
    "\n",
    "5. **Neural networks can have millions of parameters. How do you think they avoid overfitting?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b91f8",
   "metadata": {},
   "source": [
    "### The Bottom Line\n",
    "\n",
    "> **Never trust training error alone. Always evaluate on held-out test data.**\n",
    "\n",
    "> **Be skeptical of models that fit training data \"too well\" â€” they might be fitting noise.**\n",
    "\n",
    "> **Simpler models often generalize better (Occam's Razor).**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ing3513",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
